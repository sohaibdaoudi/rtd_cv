

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Changing Tire Assistant â€“ Computer Vision &amp; NLP Project ğŸš— &mdash; TimeSeriesProject  documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=5929fcd5"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="#" class="icon icon-home">
            TimeSeriesProject
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <!-- Local TOC -->
              <div class="local-toc"><ul>
<li><a class="reference internal" href="#">Changing Tire Assistant â€“ Computer Vision &amp; NLP Project ğŸš—</a><ul>
<li><a class="reference internal" href="#overview">Overview ğŸŒŸ</a></li>
<li><a class="reference internal" href="#system-features">System Features ğŸ› ï¸</a></li>
<li><a class="reference internal" href="#project-structure">Project Structure ğŸ“</a></li>
<li><a class="reference internal" href="#models-used">Models Used ğŸ§ </a></li>
<li><a class="reference internal" href="#data">Data ğŸ“Š</a><ul>
<li><a class="reference internal" href="#data-collection-methodology">Data Collection Methodology ğŸ¥</a></li>
<li><a class="reference internal" href="#dataset-structure">Dataset Structure ğŸ—ƒï¸</a></li>
</ul>
</li>
<li><a class="reference internal" href="#changing-tire-assistant-computer-vision-nlp-project-models-testing">Changing Tire Assistant - Computer Vision &amp; NLP Project: Models Testing ğŸ§ª</a></li>
<li><a class="reference internal" href="#object-detection">Object Detection ğŸ¯</a><ul>
<li><a class="reference internal" href="#yolov11-nano-implementation-guide">YOLOv11 Nano Implementation Guide ğŸ“„</a></li>
<li><a class="reference internal" href="#prerequisites">Prerequisites âœ…</a></li>
<li><a class="reference internal" href="#setup">Setup âš™ï¸</a><ul>
<li><a class="reference internal" href="#option-1-using-git-recommended-full-repository">Option 1: Using Git (Recommended - Full Repository) ğŸš€</a></li>
<li><a class="reference internal" href="#clone-the-repository">1. <strong>Clone the Repository</strong>:</a></li>
<li><a class="reference internal" href="#option-2-manual-download-zip">Option 2: Manual Download (ZIP) â¬‡ï¸</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#installation-and-execution">Installation and Execution ğŸš€</a><ul>
<li><a class="reference internal" href="#navigate-to-your-project-directory">0. Navigate to Your Project Directory ğŸ“‚</a><ul>
<li><a class="reference internal" href="#first-open-your-command-line-interface-e-g-command-prompt-powershell-terminal-anaconda-prompt-and-navigate-to-the-project-s-root-folder-replace-c-path-to-folder-with-the-actual-path-to-your-object-detection-folder">First, open your command line interface (e.g., Command Prompt, PowerShell, Terminal, Anaconda Prompt) and navigate to the projectâ€™s root folder. Replace <cite>C:path_to_folder</cite> with the actual path to your Object Detection folder.</a></li>
</ul>
</li>
<li><a class="reference internal" href="#create-a-virtual-environment-recommended-choose-one-of-the-following-methods">1. Create a Virtual Environment (Recommended) (Choose <strong>one</strong> of the following methods) ğŸ:</a></li>
<li><a class="reference internal" href="#install-dependencies">2. Install Dependencies ğŸ“¦</a><ul>
<li><a class="reference internal" href="#ensure-your-pip-is-up-to-date-if-using-venv-or-pip-within-conda-and-then-install-the-required-packages">Ensure your <cite>pip</cite> is up to date (if using <cite>venv</cite> or pip within Conda) and then install the required packages.</a></li>
<li><a class="reference internal" href="#if-using-conda-you-might-prefer-to-install-packages-using-conda-where-possible-for-example"><em>If using Conda, you might prefer to install packages using Conda where possible, for example:</em></a></li>
</ul>
</li>
<li><a class="reference internal" href="#run-detection">3. Run Detection â–¶ï¸</a><ul>
<li><a class="reference internal" href="#execute-the-detection-script-the-following-command-runs-the-detection-on-the-test-video-using-the-gpu-or-using-only-cpu-by-removing-device-0">Execute the detection script. The following command runs the detection on the test video using the GPU (or using only CPU by removing â€“device 0).</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#action-recognition">Action Recognition ğŸƒ</a></li>
<li><a class="reference internal" href="#authors">Authors ğŸ‘¥</a></li>
<li><a class="reference internal" href="#license">License ğŸ“„</a></li>
</ul>
</li>
</ul>
</div>
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="#">TimeSeriesProject</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="#" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Changing Tire Assistant â€“ Computer Vision &amp; NLP Project ğŸš—</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/index.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <a class="reference external image-reference" href="https://www.python.org/downloads/"><img alt="https://img.shields.io/badge/python-3.x-blue.svg" src="https://img.shields.io/badge/python-3.x-blue.svg" />
</a>
<a class="reference external image-reference" href="./LICENSE"><img alt="https://img.shields.io/badge/License-MIT-yellow.svg" src="https://img.shields.io/badge/License-MIT-yellow.svg" />
</a>
<section id="changing-tire-assistant-computer-vision-nlp-project">
<h1>Changing Tire Assistant â€“ Computer Vision &amp; NLP Project ğŸš—<a class="headerlink" href="#changing-tire-assistant-computer-vision-nlp-project" title="Link to this heading">ïƒ</a></h1>
<p><strong>ğŸš§ Project Status: Under Development ğŸš§</strong></p>
<p>â€”</p>
<section id="overview">
<h2>Overview ğŸŒŸ<a class="headerlink" href="#overview" title="Link to this heading">ïƒ</a></h2>
<p>This assistant leverages real-time computer vision and NLP to guide users through changing a flat tire using an egocentric (chest-mounted) camera.</p>
<p>The assistant detects tools, tracks task progress, and provides interactive, step-by-step visual and voice instructions for changing a vehicle tire.</p>
<p>â€”</p>
</section>
<section id="system-features">
<h2>System Features ğŸ› ï¸<a class="headerlink" href="#system-features" title="Link to this heading">ïƒ</a></h2>
<ul class="simple">
<li><p><strong>Real-Time Tool Detection</strong>:
- Identifies car jack, wheel wrench, etc.</p></li>
<li><p><strong>Action Recognition</strong>:
- Tracks task progression like loosening nuts, jacking the car, replacing the wheel, etc.</p></li>
<li><p><strong>Voice Assistant</strong>:
- Responds to user queries such as â€œWhatâ€™s next?â€</p></li>
<li><p><strong>Edge-Friendly Pipeline</strong>:
- Designed for deployment on mobile or embedded systems with minimal latency.</p></li>
</ul>
<p>â€”</p>
</section>
<section id="project-structure">
<h2>Project Structure ğŸ“<a class="headerlink" href="#project-structure" title="Link to this heading">ïƒ</a></h2>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>â”œâ”€â”€ action_recognition/
â”œâ”€â”€ Object Detection/
â”œâ”€â”€ UML Model
</pre></div>
</div>
<p>â€”</p>
</section>
<section id="models-used">
<h2>Models Used ğŸ§ <a class="headerlink" href="#models-used" title="Link to this heading">ïƒ</a></h2>
<ul class="simple">
<li><p><strong>Object Detection</strong>: YOLOv11n fine-tuned on tire-change-specific tools and components</p></li>
<li><p><strong>Action Recognition</strong>: We are trying different models SlowFast , TSM , TimeDistributed EfficientNetB0</p></li>
<li><p><strong>Voice Assistant</strong>: Whisper-based STT with a custom NLP pipeline for contextual understanding</p></li>
</ul>
<p>â€”</p>
</section>
<section id="data">
<h2>Data ğŸ“Š<a class="headerlink" href="#data" title="Link to this heading">ïƒ</a></h2>
<p>We collected and curated a custom dataset specifically for the tire change domain:</p>
<section id="data-collection-methodology">
<h3>Data Collection Methodology ğŸ¥<a class="headerlink" href="#data-collection-methodology" title="Link to this heading">ïƒ</a></h3>
<ul class="simple">
<li><p><strong>Primary Source</strong>: Self-collected footage changing two tires on a Renault Megane 2, recorded with Samsung A50 smartphones from chest-mounted positions</p></li>
<li><p><strong>Secondary Source</strong>: Curated YouTube videos showing different tire change scenarios and vehicle types</p></li>
<li><p><strong>Other Source</strong>: We scraped the web to gather tool specifications and case studies related to flat tires. Additionally, we recorded standard videos and extracted frames for further processing. These frames were then manually annotated to identify tools, resulting in a dataset of approximately 1,597 annotated images.</p></li>
<li><p><strong>Annotation Process</strong>: Manual annotation of action segments and tool detection bounding boxes</p></li>
</ul>
</section>
<section id="dataset-structure">
<h3>Dataset Structure ğŸ—ƒï¸<a class="headerlink" href="#dataset-structure" title="Link to this heading">ïƒ</a></h3>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>data/
â”œâ”€â”€ lower_car/              # Videos/frames of lowering the car from the jack
â”œâ”€â”€ lift_car_with_jack/     # Videos/frames of raising the car with jack
â”œâ”€â”€ tighten_bolts/          # Videos/frames of final bolt tightening with wrench
â”œâ”€â”€ initial_wrench_tighten/# Videos/frames of initial wrench positioning
â”œâ”€â”€ place_spare_tire/       # Videos/frames of positioning the spare tire
â”œâ”€â”€ remove_tire/            # Videos/frames of removing the flat tire
â”œâ”€â”€ hand_tighten_bolts/     # Videos/frames of hand-tightening bolts
â”œâ”€â”€ loosen_bolts/           # Videos/frames of loosening wheel bolts
â”œâ”€â”€ remove_bolts/           # Videos/frames of removing wheel bolts
â”œâ”€â”€ labels.csv              # Action timestamps and class annotations
â””â”€â”€ README.txt              # Dataset documentation
</pre></div>
</div>
<p><a class="reference external" href="https://github.com/user-attachments/assets/6d6bef7f-5d31-4b78-b57b-93b3566c5007">https://github.com/user-attachments/assets/6d6bef7f-5d31-4b78-b57b-93b3566c5007</a></p>
</section>
</section>
<section id="changing-tire-assistant-computer-vision-nlp-project-models-testing">
<h2>Changing Tire Assistant - Computer Vision &amp; NLP Project: Models Testing ğŸ§ª<a class="headerlink" href="#changing-tire-assistant-computer-vision-nlp-project-models-testing" title="Link to this heading">ïƒ</a></h2>
<p>This document outlines the setup and usage of the models implemented within the Changing Tire Assistant project.</p>
<p>â€”</p>
</section>
<section id="object-detection">
<h2>Object Detection ğŸ¯<a class="headerlink" href="#object-detection" title="Link to this heading">ïƒ</a></h2>
<p>This section details the implementation of the object detection model.</p>
<section id="yolov11-nano-implementation-guide">
<h3>YOLOv11 Nano Implementation Guide ğŸ“„<a class="headerlink" href="#yolov11-nano-implementation-guide" title="Link to this heading">ïƒ</a></h3>
<p><strong>Description</strong>: This model is utilized for identifying various objects relevant to the tire-changing process.</p>
</section>
<section id="prerequisites">
<h3>Prerequisites âœ…<a class="headerlink" href="#prerequisites" title="Link to this heading">ïƒ</a></h3>
<ul class="simple">
<li><p>Python 3.1X</p></li>
<li><p>Ultralytics package (version compatible with your GPU, you can ask any AI for that)</p></li>
<li><p>CUDA 11.8+ (recommended for GPU acceleration)</p></li>
</ul>
<p>â€”</p>
</section>
<section id="setup">
<h3>Setup âš™ï¸<a class="headerlink" href="#setup" title="Link to this heading">ïƒ</a></h3>
<p>You can set up the project by cloning the full repository or by cloning only the <cite>Object Detection</cite> directory using Gitâ€™s sparse checkout feature.</p>
<section id="option-1-using-git-recommended-full-repository">
<h4>Option 1: Using Git (Recommended - Full Repository) ğŸš€<a class="headerlink" href="#option-1-using-git-recommended-full-repository" title="Link to this heading">ïƒ</a></h4>
</section>
<section id="clone-the-repository">
<h4>1. <strong>Clone the Repository</strong>:<a class="headerlink" href="#clone-the-repository" title="Link to this heading">ïƒ</a></h4>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/sohaibdaoudi/ChangingTireAssistant_CV_NLP_Project.git
</pre></div>
</div>
</div></blockquote>
<ol class="arabic simple" start="2">
<li><p><strong>Navigate to the Object Detection Directory</strong>: Open your terminal or command prompt and change to the <cite>Object Detection</cite> folder within the extracted contents.</p></li>
</ol>
</section>
<section id="option-2-manual-download-zip">
<h4>Option 2: Manual Download (ZIP) â¬‡ï¸<a class="headerlink" href="#option-2-manual-download-zip" title="Link to this heading">ïƒ</a></h4>
<ol class="arabic simple">
<li><p><strong>Download the Repository</strong>:
- <strong>Full Repository</strong>: Navigate to the <a class="reference external" href="https://github.com/sohaibdaoudi/ChangingTireAssistant_CV_NLP_Project">main repository page</a> and click on â€œCodeâ€ â†’ â€œDownload ZIPâ€.
- <strong>Object Detection</strong>: A direct download for only the Object Detection folder is typically achieved by downloading the full repository and then extracting the relevant folder.</p></li>
<li><p><strong>Extract the ZIP File</strong>: Unzip the downloaded file to your desired location.</p></li>
<li><p><strong>Navigate to the Object Detection Directory</strong>: Open your terminal or command prompt and change to the <cite>Object Detection</cite> folder within the extracted contents.</p></li>
</ol>
<p>â€”</p>
</section>
</section>
</section>
<section id="installation-and-execution">
<h2>Installation and Execution ğŸš€<a class="headerlink" href="#installation-and-execution" title="Link to this heading">ïƒ</a></h2>
<section id="navigate-to-your-project-directory">
<h3>0. Navigate to Your Project Directory ğŸ“‚<a class="headerlink" href="#navigate-to-your-project-directory" title="Link to this heading">ïƒ</a></h3>
<section id="first-open-your-command-line-interface-e-g-command-prompt-powershell-terminal-anaconda-prompt-and-navigate-to-the-project-s-root-folder-replace-c-path-to-folder-with-the-actual-path-to-your-object-detection-folder">
<h4>First, open your command line interface (e.g., Command Prompt, PowerShell, Terminal, Anaconda Prompt) and navigate to the projectâ€™s root folder. Replace <cite>C:path_to_folder</cite> with the actual path to your Object Detection folder.<a class="headerlink" href="#first-open-your-command-line-interface-e-g-command-prompt-powershell-terminal-anaconda-prompt-and-navigate-to-the-project-s-root-folder-replace-c-path-to-folder-with-the-actual-path-to-your-object-detection-folder" title="Link to this heading">ïƒ</a></h4>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>C:<span class="se">\p</span>ath_to_project
</pre></div>
</div>
</section>
</section>
<section id="create-a-virtual-environment-recommended-choose-one-of-the-following-methods">
<h3>1. Create a Virtual Environment (Recommended) (Choose <strong>one</strong> of the following methods) ğŸ:<a class="headerlink" href="#create-a-virtual-environment-recommended-choose-one-of-the-following-methods" title="Link to this heading">ïƒ</a></h3>
<blockquote>
<div><ul class="simple">
<li><p><strong>Using `venv` (Pythonâ€™s built-in)</strong>:</p></li>
</ul>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>-m<span class="w"> </span>venv<span class="w"> </span>venv
</pre></div>
</div>
<ul class="simple">
<li><p>On Windows:</p></li>
</ul>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>venv<span class="se">\S</span>cripts<span class="se">\a</span>ctivate
</pre></div>
</div>
</div></blockquote>
<ul class="simple">
<li><p>On macOS/Linux:</p></li>
</ul>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">source</span><span class="w"> </span>venv/bin/activate
</pre></div>
</div>
</div></blockquote>
</div></blockquote>
<ul>
<li><p><strong>Using `conda` (Anaconda/Miniconda)</strong>:
Replace <cite>myenv</cite> with your desired environment name and your preferred compatible version of python (3.1X).</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>conda<span class="w"> </span>create<span class="w"> </span>--name<span class="w"> </span>myenv<span class="w"> </span>python
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>conda<span class="w"> </span>activate<span class="w"> </span>myenv
</pre></div>
</div>
</li>
</ul>
</div></blockquote>
</section>
<section id="install-dependencies">
<h3>2. Install Dependencies ğŸ“¦<a class="headerlink" href="#install-dependencies" title="Link to this heading">ïƒ</a></h3>
<section id="ensure-your-pip-is-up-to-date-if-using-venv-or-pip-within-conda-and-then-install-the-required-packages">
<h4>Ensure your <cite>pip</cite> is up to date (if using <cite>venv</cite> or pip within Conda) and then install the required packages.<a class="headerlink" href="#ensure-your-pip-is-up-to-date-if-using-venv-or-pip-within-conda-and-then-install-the-required-packages" title="Link to this heading">ïƒ</a></h4>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>-m<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>--upgrade<span class="w"> </span>pip
pip<span class="w"> </span>install<span class="w"> </span><span class="nv">ultralytics</span><span class="o">==</span>XX.XX.XX<span class="w"> </span>opencv-python<span class="o">==</span>XX.XX.XX
</pre></div>
</div>
</section>
<section id="if-using-conda-you-might-prefer-to-install-packages-using-conda-where-possible-for-example">
<h4><em>If using Conda, you might prefer to install packages using Conda where possible, for example:</em><a class="headerlink" href="#if-using-conda-you-might-prefer-to-install-packages-using-conda-where-possible-for-example" title="Link to this heading">ïƒ</a></h4>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># conda install anaconda # For a fuller anaconda distribution within the environment if needed</span>
<span class="c1"># conda install pip # To ensure pip is available in the conda env</span>
<span class="c1"># pip install ultralytics==XX.XX.XX opencv-python==XX.XX.XX</span>
</pre></div>
</div>
</section>
</section>
<section id="run-detection">
<h3>3. Run Detection â–¶ï¸<a class="headerlink" href="#run-detection" title="Link to this heading">ïƒ</a></h3>
<section id="execute-the-detection-script-the-following-command-runs-the-detection-on-the-test-video-using-the-gpu-or-using-only-cpu-by-removing-device-0">
<h4>Execute the detection script. The following command runs the detection on the test video using the GPU (or using only CPU by removing â€“device 0).<a class="headerlink" href="#execute-the-detection-script-the-following-command-runs-the-detection-on-the-test-video-using-the-gpu-or-using-only-cpu-by-removing-device-0" title="Link to this heading">ïƒ</a></h4>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>yolo_detect.py<span class="w"> </span>--model<span class="w"> </span>best.pt<span class="w"> </span>--source<span class="w"> </span>test.mp4<span class="w"> </span>--resolution<span class="w"> </span>1280x720<span class="w"> </span>--device<span class="w"> </span><span class="m">0</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">--model</span> <span class="pre">best.pt</span></code>: Specifies the path to your trained model weights.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--source</span> <span class="pre">test.mp4</span></code>: Specifies the path to your input video or image source.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--resolution</span> <span class="pre">1280x720</span></code>: Sets the input resolution. This flag supports various input sizes.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--device</span> <span class="pre">0</span></code>: This command will let the test run on GPU, you can delete it if you want to use only CPU.</p></li>
</ul>
<p>â€”</p>
</section>
</section>
</section>
<section id="action-recognition">
<h2>Action Recognition ğŸƒ<a class="headerlink" href="#action-recognition" title="Link to this heading">ïƒ</a></h2>
<p><em>(Details for the Action Recognition module, including specific models, requirements, setup, installation, and execution, should be added here following a similar structure to the Object Detection section.)</em></p>
<p>â€”</p>
</section>
<section id="authors">
<h2>Authors ğŸ‘¥<a class="headerlink" href="#authors" title="Link to this heading">ïƒ</a></h2>
<p>This project is developed and maintained by:</p>
<ul class="simple">
<li><p><strong>SOHAIB DAOUDI</strong> â€“ <a class="reference external" href="mailto:soh&#46;daoudi&#37;&#52;&#48;gmail&#46;com">soh<span>&#46;</span>daoudi<span>&#64;</span>gmail<span>&#46;</span>com</a></p></li>
<li><p><strong>MAROUANE MAJIDI</strong> â€“ <a class="reference external" href="mailto:majidi&#46;marouane0&#37;&#52;&#48;gmail&#46;com">majidi<span>&#46;</span>marouane0<span>&#64;</span>gmail<span>&#46;</span>com</a></p></li>
</ul>
<p>â€”</p>
</section>
<section id="license">
<h2>License ğŸ“„<a class="headerlink" href="#license" title="Link to this heading">ïƒ</a></h2>
<p>This project is licensed under the <a class="reference external" href="https://opensource.org/licenses/MIT">MIT License</a>. Please see the <code class="docutils literal notranslate"><span class="pre">LICENSE</span></code> file in the repository for full license text and details.</p>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, DAOUDI &amp; MAJIDI.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>